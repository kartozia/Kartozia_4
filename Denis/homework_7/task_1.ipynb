{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Named entity recognition\n",
    "\n",
    "Для заданной тестовой выборки построить модель для обнаружения и классификации именованных сущностей (named entities). На базе корпуса CoNLL 2002.  \n",
    "\n",
    "Чем больше baseline'ов вы превзойдете, тем выше ваша оценка\n",
    "Метрика качества f1 (f1_macro) (чем выше, тем лучше)\n",
    " \n",
    "baseline 1: 0.0604      random labels  \n",
    "baseline 2: 0.3966      PoS features + logistic regression  \n",
    "baseline 3: 0.7559      word2vec cbow embedding + baseline 2 + svm    \n",
    "\n",
    "Пока мы рассмотрели только линейные модели - поэтому в примерах есть только они. Желательно при решении домашнего задания пользоваться линейными моделями. Таким образом, основные цели задания - feature engineering, hyperparam tuning & model selection.\n",
    "\n",
    "! Your results must be reproducible. Если ваша модель - стохастическая, то вы явно должны задавать все seed и random_state в параметрах моделей  \n",
    "! Вы должны использовать df_test только для измерения качества конечной обученной модели. \n",
    "\n",
    "bonus, think about:  \n",
    "1. how can you exploit that words belong to some sentence?\n",
    "2. why we selected f1 score with macro averaging as our classification quality measure? What other metrics are suitable   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "SEED=1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNP</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  next-next-pos next-next-word next-pos      next-word  pos    prev-pos  \\\n",
       "0           NNS  demonstrators       IN             of  NNS  __START1__   \n",
       "1           VBP           have      NNS  demonstrators   IN         NNS   \n",
       "2           VBN        marched      VBP           have  NNS          IN   \n",
       "3            IN        through      VBN        marched  VBP         NNS   \n",
       "4           NNP         London       IN        through  VBN         VBP   \n",
       "\n",
       "  prev-prev-pos prev-prev-word      prev-word  sentence_idx           word tag  \n",
       "0    __START2__     __START2__     __START1__           1.0      Thousands   O  \n",
       "1    __START1__     __START1__      Thousands           1.0             of   O  \n",
       "2           NNS      Thousands             of           1.0  demonstrators   O  \n",
       "3            IN             of  demonstrators           1.0           have   O  \n",
       "4           NNS  demonstrators           have           1.0        marched   O  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/ner_short.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of sentences\n",
    "df.sentence_idx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        0.852828\n",
       "B-geo    0.027604\n",
       "B-gpe    0.020935\n",
       "B-org    0.020247\n",
       "I-per    0.017795\n",
       "B-tim    0.016927\n",
       "B-per    0.015312\n",
       "I-org    0.013937\n",
       "I-geo    0.005383\n",
       "I-tim    0.004247\n",
       "B-art    0.001376\n",
       "I-gpe    0.000837\n",
       "I-art    0.000748\n",
       "B-eve    0.000628\n",
       "I-eve    0.000508\n",
       "B-nat    0.000449\n",
       "I-nat    0.000239\n",
       "Name: tag, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "df.tag.value_counts(normalize=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentence length\n",
    "tdf = df.set_index('sentence_idx')\n",
    "tdf['length'] = df.groupby('sentence_idx').tag.count()\n",
    "df = tdf.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode categorial variables\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['pos'] = le.fit_transform(df.pos)\n",
    "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
    "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
    "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
    "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>9</td>\n",
       "      <td>of</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>have</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>marched</td>\n",
       "      <td>33</td>\n",
       "      <td>have</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>through</td>\n",
       "      <td>32</td>\n",
       "      <td>marched</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>London</td>\n",
       "      <td>9</td>\n",
       "      <td>through</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_idx  next-next-pos next-next-word  next-pos      next-word  pos  \\\n",
       "0           1.0             18  demonstrators         9             of   18   \n",
       "1           1.0             33           have        18  demonstrators    9   \n",
       "2           1.0             32        marched        33           have   18   \n",
       "3           1.0              9        through        32        marched   33   \n",
       "4           1.0             16         London         9        through   32   \n",
       "\n",
       "   prev-pos  prev-prev-pos prev-prev-word      prev-word           word tag  \\\n",
       "0        39             40     __START2__     __START1__      Thousands   O   \n",
       "1        18             39     __START1__      Thousands             of   O   \n",
       "2         9             18      Thousands             of  demonstrators   O   \n",
       "3        18              9             of  demonstrators           have   O   \n",
       "4        33             18  demonstrators           have        marched   O   \n",
       "\n",
       "   length  \n",
       "0      48  \n",
       "1      48  \n",
       "2      48  \n",
       "3      48  \n",
       "4      48  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 50155\n",
      "test 16719\n"
     ]
    }
   ],
   "source": [
    "# splitting\n",
    "y = LabelEncoder().fit_transform(df.tag)\n",
    "\n",
    "df_train, df_test, y_train, y_test = model_selection.train_test_split(df, y, stratify=y, \n",
    "                                                                      test_size=0.25, random_state=SEED, shuffle=True)\n",
    "print('train', df_train.shape[0])\n",
    "print('test', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some wrappers to work with word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from collections import defaultdict\n",
    "#from glove import Corpus, Glove\n",
    "\n",
    "   \n",
    "class Word2VecWrapper(TransformerMixin):\n",
    "    def __init__(self, window=5,negative=5, size=100, iter=100, is_cbow=False, random_state=SEED):\n",
    "        self.window_ = window\n",
    "        self.negative_ = negative\n",
    "        self.size_ = size\n",
    "        self.iter_ = iter\n",
    "        self.is_cbow_ = is_cbow\n",
    "        self.w2v = None\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def get_size(self):\n",
    "        return self.size_\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        X: list of strings\n",
    "        \"\"\"\n",
    "        sentences_list = [x.split() for x in X]\n",
    "        self.w2v = Word2Vec(sentences_list, \n",
    "                            window=self.window_,\n",
    "                            negative=self.negative_, \n",
    "                            size=self.size_, \n",
    "                            iter=self.iter_,\n",
    "                            sg=not self.is_cbow_, seed=self.random_state)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def has(self, word):\n",
    "        return word in self.w2v\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X: a list of words\n",
    "        \"\"\"\n",
    "        if self.w2v is None:\n",
    "            raise Exception('model not fitted')\n",
    "        return np.array([self.w2v[w] if w in self.w2v else np.zeros(self.size_) for w in X ])\n",
    "    \n",
    "\n",
    "class GloveWrapper(TransformerMixin):\n",
    "    def __init__(self, window=5, learning_rate=0.05, size=100, epochs=100, random_state=SEED, verbose=False):\n",
    "        self.window_ = window\n",
    "        self.learning_rate_ = learning_rate\n",
    "        self.size_ = size\n",
    "        self.epochs_ = epochs\n",
    "        self.glove = None\n",
    "        self.random_state = random_state\n",
    "        self.verbose_ = verbose\n",
    "    \n",
    "    def get_size(self):\n",
    "        return self.size_\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        X: list of strings\n",
    "        \"\"\"\n",
    "        sentences_list = [x.split() for x in X]\n",
    "        corpus = Corpus()\n",
    "        corpus.fit(sentences_list, window=self.window_)\n",
    "        self.glove = Glove(no_components=self.size_, \n",
    "                           learning_rate=self.learning_rate_, \n",
    "                           random_state=self.random_state)\n",
    "        self.glove.fit(corpus.matrix, \n",
    "                  epochs=self.epochs_, \n",
    "                  no_threads=4, verbose=self.verbose_)\n",
    "        self.glove.add_dictionary(corpus.dictionary)\n",
    "        return self\n",
    "    \n",
    "    def has(self, word):\n",
    "        return word in self.glove.dictionary\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X: list of words\n",
    "        \"\"\"\n",
    "        if self.glove is None:\n",
    "            raise Exception('model not fitted')\n",
    "            \n",
    "        return np.array([self.glove.word_vectors[self.glove.dictionary[w]] if w in self.glove.dictionary else np.zeros(self.size_) \n",
    "                         for w in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.1 s, sys: 454 ms, total: 21.5 s\n",
      "Wall time: 7.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# we have to fit embedding models on whole dataset as they depend on word order\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "# notice, that our dataset has window=2\n",
    "sentences_list = [x.strip() for x in ' '.join(df.word).split('.')]\n",
    "\n",
    "w2v_cbow = Word2VecWrapper(window=2, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
    "w2v_cbow.fit(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counts(column,Y):\n",
    "    counts = dict()\n",
    "    for target in np.unique(Y):\n",
    "        counts[target] = dict()\n",
    "        for elem in np.unique(column):\n",
    "            counts[target][elem] = (max(0,(((column == elem) & (Y == target)).sum())))/((column == elem).sum())\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_counts(name):\n",
    "    counts_dict = counts(df_train[name],y_train)\n",
    "    counts_val_train = []\n",
    "    for i in range(df_train.shape[0]):\n",
    "        counts_val_train.append(counts_dict[y_train[i]][df_train[name].values[i]])\n",
    "    counts_val_test = []\n",
    "    for i in range(df_test.shape[0]):\n",
    "        counts_val_test.append(counts_dict[y_test[i]][df_test[name].values[i]])\n",
    "    return counts_val_train, counts_val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_train = []\n",
    "counts_test = []\n",
    "for col in ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']:\n",
    "    counts_val_train, counts_val_test = to_counts(col)\n",
    "    counts_train.append(counts_val_train)\n",
    "    counts_test.append(counts_val_test)\n",
    "X_counts_train = pd.DataFrame(np.array(counts_train).T,columns=['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos'])\n",
    "X_counts_test = pd.DataFrame(np.array(counts_test).T,columns=['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864933</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.656173</td>\n",
       "      <td>0.769064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886589</td>\n",
       "      <td>0.870662</td>\n",
       "      <td>0.926883</td>\n",
       "      <td>0.908356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997922</td>\n",
       "      <td>0.964962</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.926883</td>\n",
       "      <td>0.846100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997922</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.752735</td>\n",
       "      <td>0.846100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.093364</td>\n",
       "      <td>0.089918</td>\n",
       "      <td>0.011631</td>\n",
       "      <td>0.015037</td>\n",
       "      <td>0.020552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.997922</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>0.752735</td>\n",
       "      <td>0.828609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.996438</td>\n",
       "      <td>0.928810</td>\n",
       "      <td>0.873957</td>\n",
       "      <td>0.987038</td>\n",
       "      <td>0.828609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.985690</td>\n",
       "      <td>0.964962</td>\n",
       "      <td>0.747801</td>\n",
       "      <td>0.987038</td>\n",
       "      <td>0.890899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.985690</td>\n",
       "      <td>0.633261</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>0.960905</td>\n",
       "      <td>0.909440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.993836</td>\n",
       "      <td>0.781049</td>\n",
       "      <td>0.726111</td>\n",
       "      <td>0.987038</td>\n",
       "      <td>0.830663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.099457</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.015766</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.048128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988066</td>\n",
       "      <td>0.911846</td>\n",
       "      <td>0.656173</td>\n",
       "      <td>0.769064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.997922</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.724841</td>\n",
       "      <td>0.724841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.781049</td>\n",
       "      <td>0.836663</td>\n",
       "      <td>0.944652</td>\n",
       "      <td>0.914071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.986295</td>\n",
       "      <td>0.714026</td>\n",
       "      <td>0.715066</td>\n",
       "      <td>0.857793</td>\n",
       "      <td>0.908356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.991641</td>\n",
       "      <td>0.901713</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.931063</td>\n",
       "      <td>0.960114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.983051</td>\n",
       "      <td>0.620853</td>\n",
       "      <td>0.819724</td>\n",
       "      <td>0.857793</td>\n",
       "      <td>0.875374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906784</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.960905</td>\n",
       "      <td>0.866516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.157747</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.019224</td>\n",
       "      <td>0.018692</td>\n",
       "      <td>0.032033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.157747</td>\n",
       "      <td>0.020538</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.041750</td>\n",
       "      <td>0.019393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.803194</td>\n",
       "      <td>0.633261</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.752735</td>\n",
       "      <td>0.914071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.067628</td>\n",
       "      <td>0.025244</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.015080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.985690</td>\n",
       "      <td>0.633261</td>\n",
       "      <td>0.747801</td>\n",
       "      <td>0.960905</td>\n",
       "      <td>0.828609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.993836</td>\n",
       "      <td>0.781049</td>\n",
       "      <td>0.665768</td>\n",
       "      <td>0.987038</td>\n",
       "      <td>0.877903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.972516</td>\n",
       "      <td>0.784803</td>\n",
       "      <td>0.747801</td>\n",
       "      <td>0.960905</td>\n",
       "      <td>0.769064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.972516</td>\n",
       "      <td>0.988066</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.927948</td>\n",
       "      <td>0.937422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996055</td>\n",
       "      <td>0.820638</td>\n",
       "      <td>0.987038</td>\n",
       "      <td>0.908356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.985690</td>\n",
       "      <td>0.988066</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.944652</td>\n",
       "      <td>0.828609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.972516</td>\n",
       "      <td>0.906784</td>\n",
       "      <td>0.870662</td>\n",
       "      <td>0.944652</td>\n",
       "      <td>0.924939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988066</td>\n",
       "      <td>0.882075</td>\n",
       "      <td>0.960905</td>\n",
       "      <td>0.866516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50125</th>\n",
       "      <td>0.997922</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.919400</td>\n",
       "      <td>0.930636</td>\n",
       "      <td>0.957672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50126</th>\n",
       "      <td>0.170005</td>\n",
       "      <td>0.065157</td>\n",
       "      <td>0.115714</td>\n",
       "      <td>0.092928</td>\n",
       "      <td>0.092928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50127</th>\n",
       "      <td>0.997922</td>\n",
       "      <td>0.906784</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.752735</td>\n",
       "      <td>0.914894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50128</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906784</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.974657</td>\n",
       "      <td>0.937422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50129</th>\n",
       "      <td>0.124650</td>\n",
       "      <td>0.112069</td>\n",
       "      <td>0.080863</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50130</th>\n",
       "      <td>0.972516</td>\n",
       "      <td>0.877805</td>\n",
       "      <td>0.819724</td>\n",
       "      <td>0.724841</td>\n",
       "      <td>0.724841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50131</th>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.851918</td>\n",
       "      <td>0.875374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50132</th>\n",
       "      <td>0.768566</td>\n",
       "      <td>0.906784</td>\n",
       "      <td>0.882075</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.925864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50133</th>\n",
       "      <td>0.170005</td>\n",
       "      <td>0.044547</td>\n",
       "      <td>0.023915</td>\n",
       "      <td>0.054624</td>\n",
       "      <td>0.024287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50134</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996055</td>\n",
       "      <td>0.747801</td>\n",
       "      <td>0.987038</td>\n",
       "      <td>0.828609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50135</th>\n",
       "      <td>0.985690</td>\n",
       "      <td>0.988066</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.987038</td>\n",
       "      <td>0.930254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50136</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784803</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.851918</td>\n",
       "      <td>0.767524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50137</th>\n",
       "      <td>0.222789</td>\n",
       "      <td>0.019526</td>\n",
       "      <td>0.049354</td>\n",
       "      <td>0.037773</td>\n",
       "      <td>0.031729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50138</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996055</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>0.830663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50139</th>\n",
       "      <td>0.983051</td>\n",
       "      <td>0.964962</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.656173</td>\n",
       "      <td>0.769064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50140</th>\n",
       "      <td>0.996438</td>\n",
       "      <td>0.995885</td>\n",
       "      <td>0.747801</td>\n",
       "      <td>0.656173</td>\n",
       "      <td>0.866516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50141</th>\n",
       "      <td>0.222789</td>\n",
       "      <td>0.105647</td>\n",
       "      <td>0.103778</td>\n",
       "      <td>0.029459</td>\n",
       "      <td>0.018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50142</th>\n",
       "      <td>0.985690</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.987038</td>\n",
       "      <td>0.830663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50143</th>\n",
       "      <td>0.986295</td>\n",
       "      <td>0.906784</td>\n",
       "      <td>0.870662</td>\n",
       "      <td>0.796400</td>\n",
       "      <td>0.830663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50144</th>\n",
       "      <td>0.986295</td>\n",
       "      <td>0.906784</td>\n",
       "      <td>0.870662</td>\n",
       "      <td>0.796400</td>\n",
       "      <td>0.830663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50145</th>\n",
       "      <td>0.222789</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.049601</td>\n",
       "      <td>0.040348</td>\n",
       "      <td>0.018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50146</th>\n",
       "      <td>0.803194</td>\n",
       "      <td>0.864933</td>\n",
       "      <td>0.856982</td>\n",
       "      <td>0.752735</td>\n",
       "      <td>0.828609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50147</th>\n",
       "      <td>0.993836</td>\n",
       "      <td>0.901713</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>0.886957</td>\n",
       "      <td>0.866516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50148</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996055</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.960905</td>\n",
       "      <td>0.866516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50149</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906784</td>\n",
       "      <td>0.870662</td>\n",
       "      <td>0.656173</td>\n",
       "      <td>0.828609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50150</th>\n",
       "      <td>0.985690</td>\n",
       "      <td>0.988066</td>\n",
       "      <td>0.747801</td>\n",
       "      <td>0.960905</td>\n",
       "      <td>0.866516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50151</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988066</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.656173</td>\n",
       "      <td>0.879182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50152</th>\n",
       "      <td>0.993836</td>\n",
       "      <td>0.781049</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.987038</td>\n",
       "      <td>0.846100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50153</th>\n",
       "      <td>0.099457</td>\n",
       "      <td>0.066351</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.045610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50154</th>\n",
       "      <td>0.985690</td>\n",
       "      <td>0.984887</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.944652</td>\n",
       "      <td>0.937422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50155 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pos  next-pos  next-next-pos  prev-pos  prev-prev-pos\n",
       "0      1.000000  0.864933       0.771429  0.656173       0.769064\n",
       "1      1.000000  0.886589       0.870662  0.926883       0.908356\n",
       "2      0.997922  0.964962       0.915347  0.926883       0.846100\n",
       "3      0.997922  0.879809       0.896825  0.752735       0.846100\n",
       "4      0.093364  0.089918       0.011631  0.015037       0.020552\n",
       "5      0.997922  0.879809       0.782200  0.752735       0.828609\n",
       "6      0.996438  0.928810       0.873957  0.987038       0.828609\n",
       "7      0.985690  0.964962       0.747801  0.987038       0.890899\n",
       "8      0.985690  0.633261       0.782200  0.960905       0.909440\n",
       "9      0.993836  0.781049       0.726111  0.987038       0.830663\n",
       "10     0.099457  0.007595       0.015766  0.101000       0.048128\n",
       "11     1.000000  0.988066       0.911846  0.656173       0.769064\n",
       "12     0.997922  0.879809       0.915347  0.724841       0.724841\n",
       "13     0.829787  0.781049       0.836663  0.944652       0.914071\n",
       "14     0.986295  0.714026       0.715066  0.857793       0.908356\n",
       "15     0.991641  0.901713       0.925311  0.931063       0.960114\n",
       "16     0.983051  0.620853       0.819724  0.857793       0.875374\n",
       "17     1.000000  0.906784       0.915347  0.960905       0.866516\n",
       "18     0.157747  0.031600       0.019224  0.018692       0.032033\n",
       "19     0.157747  0.020538       0.035714  0.041750       0.019393\n",
       "20     0.803194  0.633261       0.925311  0.752735       0.914071\n",
       "21     0.004377  0.067628       0.025244  0.009452       0.015080\n",
       "22     0.985690  0.633261       0.747801  0.960905       0.828609\n",
       "23     0.993836  0.781049       0.665768  0.987038       0.877903\n",
       "24     0.972516  0.784803       0.747801  0.960905       0.769064\n",
       "25     0.972516  0.988066       0.915347  0.927948       0.937422\n",
       "26     1.000000  0.996055       0.820638  0.987038       0.908356\n",
       "27     0.985690  0.988066       0.925311  0.944652       0.828609\n",
       "28     0.972516  0.906784       0.870662  0.944652       0.924939\n",
       "29     1.000000  0.988066       0.882075  0.960905       0.866516\n",
       "...         ...       ...            ...       ...            ...\n",
       "50125  0.997922  0.879809       0.919400  0.930636       0.957672\n",
       "50126  0.170005  0.065157       0.115714  0.092928       0.092928\n",
       "50127  0.997922  0.906784       0.915347  0.752735       0.914894\n",
       "50128  1.000000  0.906784       0.915347  0.974657       0.937422\n",
       "50129  0.124650  0.112069       0.080863  0.010002       0.020408\n",
       "50130  0.972516  0.877805       0.819724  0.724841       0.724841\n",
       "50131  0.980769  0.879809       0.925311  0.851918       0.875374\n",
       "50132  0.768566  0.906784       0.882075  0.897959       0.925864\n",
       "50133  0.170005  0.044547       0.023915  0.054624       0.024287\n",
       "50134  1.000000  0.996055       0.747801  0.987038       0.828609\n",
       "50135  0.985690  0.988066       0.915347  0.987038       0.930254\n",
       "50136  1.000000  0.784803       0.896825  0.851918       0.767524\n",
       "50137  0.222789  0.019526       0.049354  0.037773       0.031729\n",
       "50138  1.000000  0.996055       0.896825  0.998573       0.830663\n",
       "50139  0.983051  0.964962       0.915347  0.656173       0.769064\n",
       "50140  0.996438  0.995885       0.747801  0.656173       0.866516\n",
       "50141  0.222789  0.105647       0.103778  0.029459       0.018868\n",
       "50142  0.985690  0.879809       0.915347  0.987038       0.830663\n",
       "50143  0.986295  0.906784       0.870662  0.796400       0.830663\n",
       "50144  0.986295  0.906784       0.870662  0.796400       0.830663\n",
       "50145  0.222789  0.336634       0.049601  0.040348       0.018868\n",
       "50146  0.803194  0.864933       0.856982  0.752735       0.828609\n",
       "50147  0.993836  0.901713       0.782200  0.886957       0.866516\n",
       "50148  1.000000  0.996055       0.896825  0.960905       0.866516\n",
       "50149  1.000000  0.906784       0.870662  0.656173       0.828609\n",
       "50150  0.985690  0.988066       0.747801  0.960905       0.866516\n",
       "50151  1.000000  0.988066       0.915347  0.656173       0.879182\n",
       "50152  0.993836  0.781049       0.915347  0.987038       0.846100\n",
       "50153  0.099457  0.066351       0.013233  0.101000       0.045610\n",
       "50154  0.985690  0.984887       0.915347  0.944652       0.937422\n",
       "\n",
       "[50155 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "embedding = w2v_cbow\n",
    "X_train = sp.hstack([\n",
    "    embedding.transform(df_train.word),\n",
    "    embedding.transform(df_train['next-word']),\n",
    "    embedding.transform(df_train['next-next-word']),\n",
    "    embedding.transform(df_train['prev-word']),\n",
    "    embedding.transform(df_train['prev-prev-word']),\n",
    "    X_counts_train])\n",
    "X_test = sp.hstack([\n",
    "    embedding.transform(df_test.word),\n",
    "    embedding.transform(df_test['next-word']),\n",
    "    embedding.transform(df_test['next-next-word']),\n",
    "    embedding.transform(df_test['prev-word']),\n",
    "    embedding.transform(df_test['prev-prev-word']),\n",
    "    X_counts_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50155x1505 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 57925775 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 35s, sys: 7.41 s, total: 4min 43s\n",
      "Wall time: 46min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "model = LogisticRegressionCV(penalty='l2', cv=5, multi_class='ovr', random_state=SEED, n_jobs=8,solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.967905376066\n",
      "test 0.818954521891\n"
     ]
    }
   ],
   "source": [
    "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
