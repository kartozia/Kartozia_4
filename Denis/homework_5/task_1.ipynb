{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ДЗ №5. Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEED = 17\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression:\n",
    "    def __init__(self, step = 0.01, tol = 1e-4, max_iter=2000, verbose=False, random_state=SEED):\n",
    "        self.max_iter = max_iter # max iter count of gradient descent\n",
    "        self.step = step # step of descent in the direction of antigradient\n",
    "        self.tol = tol # we compare norm of gradient with that threshold\n",
    "        self._w = None # w_1\n",
    "        self._intercept = None # w_0\n",
    "        self.random_state = random_state \n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        estimate target variable \"y\" based on features X \n",
    "        \"\"\"\n",
    "        y_pred = self._w*X + self._intercept #my code\n",
    "        assert y_pred.shape[0] == X.shape[0]\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        MSE\n",
    "        X - features\n",
    "        y - true values of target variable\n",
    "        \"\"\"\n",
    "        return np.mean((y - self.predict(X))**2)\n",
    "    \n",
    "    def _gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute gradient of MSE subject to w_1, w_0\n",
    "        X - features\n",
    "        y - true values of target variable\n",
    "        \"\"\"\n",
    "        grad_w = -np.mean((y-self._w*X-self._intercept)*X)\n",
    "        grad_intercept = -np.mean(y-self._w*X-self._intercept)\n",
    "        # YOUR CODE HERE\n",
    "        return grad_w, grad_intercept\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train model with gradient descent\n",
    "        X - features\n",
    "        y - true values of target variable\n",
    "        \"\"\"\n",
    "        # for reproducable results\n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        # initialize weights\n",
    "        self._w, self._intercept = np.random.randn(2)\n",
    "        # perform gradient descent\n",
    "        for iter in range(self.max_iter):\n",
    "            # compute gradient at current W\n",
    "            grad_w, grad_intercept = self._gradient(X, y)\n",
    "            \n",
    "            # make step, update W\n",
    "            \n",
    "            self._w = self._w - self.step*grad_w # YOUR CODE HERE\n",
    "            self._intercept = self._intercept - self.step*grad_intercept# YOUR CODE HERE\n",
    "            \n",
    "            # compute gradient norm            \n",
    "            grad_norm = np.sqrt(grad_w **2 + grad_intercept**2)# YOUR CODE HERE\n",
    "            \n",
    "            # people like to watch how the error is reducing during iterations \n",
    "            if self.verbose:\n",
    "                mse_score = self.score(X, y)\n",
    "                print('iteration %d, MSE = %f, ||grad|| = %f' % (iter, mse_score, grad_norm))\n",
    "                \n",
    "            # compare gradient norm with threshold\n",
    "            if grad_norm < self.tol:\n",
    "                print('model converged')\n",
    "                return self\n",
    "        print('model did not converge')\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data = datasets.load_boston()\n",
    "boston_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(boston_data['data'], columns=boston_data['feature_names'])\n",
    "df['target'] = boston_data['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# реализуем функцию, которая считает MSE \n",
    "def mse_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true - true values of target variable\n",
    "    y_pred - predicted values of target variable \n",
    "    \"\"\"\n",
    "    result = np.mean((y_true - y_pred)**2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# разбили датасет в соотношении 60:40\n",
    "df_train, df_test = train_test_split(df, test_size=0.4, random_state=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# обучите модель на df_train c verbose=True\n",
    "# Обратите внимание на отладочный вывод, ваша ошибка MSE должна уменьшаться с каждой итерацией\n",
    "# мы хотим научится предсказывать значение target по признаку CRIM\n",
    "model = SimpleLinearRegression(verbose=True)\n",
    "model.fit(X=df_train['CRIM'], y=df_train['target'])\n",
    "mse_train_score = mse_score(df_train['target'], model.predict(df_train['CRIM']))\n",
    "print('MSE on train:', mse_train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE on train: 73.31274157452383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # посчитали качество обученной модели на df_test\n",
    "mse_test_score = mse_score(df_test['target'], model.predict(df_test['CRIM']))\n",
    "print('MSE on test:', mse_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE on test: 74.28787061058355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
